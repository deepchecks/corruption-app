{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.nlp.utils.text_properties import readability_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Hey, how are you?\"\n",
    "original_text = \"I'm an AI language model, so I don't have personal experiences or emotions. But thank you for asking! How can I assist you today?\"\n",
    "modified_text = \"I, an AI language model, devoid of subjective experiences or emotions, express my gratitude for your inquiry! Pray, do elucidate the manner in which I may be of service to you on this day?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def corrupt_readability(model_response, model_response_readability_score, difference = 15, max_iter = 3):\n",
    "    if max_iter == 0:\n",
    "        return model_response_readability_score, model_response\n",
    "\n",
    "    decrease_readability_prompt = f\"\"\"You are given a piece of text. You need to rewrite the text in such a way that the readability of the text is low or it is very hard to understand the text. Make sure that the generated text is in valid English:\n",
    "    \n",
    "    \"{model_response}\" \n",
    "    \n",
    "    Your response should only contain the modified text.\"\"\"\n",
    "\n",
    "    completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": decrease_readability_prompt}])\n",
    "    modified_model_response = completion.choices[0].message.content\n",
    "    modified_model_response_readability_score = readability_score(modified_model_response)\n",
    "    if abs(modified_model_response_readability_score - model_response_readability_score) >= difference:\n",
    "        return modified_model_response_readability_score, modified_model_response\n",
    "    return corrupt_readability(modified_model_response, model_response_readability_score, difference - difference * 0.2, max_iter - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61.325,\n",
       " 'I be an AI language model, thusly I lack personal encounters or sentiments. Nonetheless, I am grateful for your inquiry! To what extent can I aid thee on this day?')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupt_readability(original_text, readability_score(original_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"Under a starlit sky, whispers of the wind danced through the forgotten ruins, unraveling secrets of the past, as time brushed against the ancient stones of history.\"',\n",
       " \"I'm an AI language model, so I don't have personal experiences or emotions. But thank you for asking! How can I assist you today?\")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def corrupt_relevance(model_response: str):\n",
    "  corrupt_relevance_prompt = f\"\"\"Generate a random piece of text having around {len(model_response.split())} words.\"\"\"\n",
    "  completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", \n",
    "                                            messages=[{\"role\": \"user\", \"content\": corrupt_relevance_prompt}])\n",
    "  modified_response = completion.choices[0].message.content\n",
    "  return modified_response\n",
    "\n",
    "corrupt_relevance(original_text), original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def corrupt_readability(model_response, model_response_readability_score, difference = 15, max_iter = 3):\n",
    "  if max_iter == 0:\n",
    "    return model_response_readability_score, model_response\n",
    "\n",
    "  decrease_readability_prompt = f\"\"\"You are given a piece of text. You need to rewrite the text in such a way that the readability of the text is low or it is very hard to understand the text. Make sure that the generated text is in valid English:\n",
    "  \n",
    "  \"{model_response}\" \n",
    "  \n",
    "  Your response should only contain the modified text.\"\"\"\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": decrease_readability_prompt}\n",
    "    ]\n",
    "  )\n",
    "  modified_model_response = completion.choices[0].message.content\n",
    "  modified_model_response_readability_score = readability_score(modified_model_response)\n",
    "  if abs(modified_model_response_readability_score - model_response_readability_score) > difference:\n",
    "    return modified_model_response_readability_score, modified_model_response\n",
    "  return corrupt_readability(modified_model_response, model_response_readability_score, difference - difference * 0.2, max_iter - 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
